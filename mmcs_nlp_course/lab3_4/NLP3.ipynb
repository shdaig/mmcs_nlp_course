{
 "cells": [
  {
   "cell_type": "raw",
   "id": "652f4a01-b8e7-4992-a587-53ddafe1a778",
   "metadata": {},
   "source": [
    "Голенищев Артём, ИИ-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3580a5-1d6f-4823-abf2-14d48c3cbfdb",
   "metadata": {},
   "source": [
    "---\n",
    "# Задание 3. Применение RNN для прогнозирования отношения в рецензиях на фильмы."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d8605d-d203-48a2-9701-3e66877e895e",
   "metadata": {},
   "source": [
    "- Реализовать многослойную рекуррентную нейронную сеть для смыслового анализа рецензий на фильмы IMDb. ✅\n",
    "\n",
    "- Использовать пакетное обучение RNN. ✅\n",
    "\n",
    "- Применять слой LSTM для учета долгосрочных эффектов. Поместить слой LSTM внутрь оболочки Bidirectional. ✅\n",
    "\n",
    "### Отчетность\n",
    "Отчет по заданию должен быть оформлен в виде ноутбука с прокомментированным кодом и результатами запуска кода. Ноутбук с отчетом прикрепите к странице до 31 мая (включительно)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6eca3e-5332-4a50-9f3a-3484acfa6865",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "### Подключение модулей и библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bcebc95-635b-4bc9-9457-f9e4ad361ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Artyom\\anaconda3\\envs\\nlp-env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import os as os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from html.parser import HTMLParser\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a8ca7e-9601-4e36-8272-9b5daaaf171f",
   "metadata": {},
   "source": [
    "---\n",
    "### План подготовки данных\n",
    "\n",
    "1. Создать объект набора данных TensorFlow и расщепить его на обучающую, испытательную и проверочную части;\n",
    "2. Идентифицировать уникальные слова в обучающем наборе;\n",
    "3. Отобразить каждое уникальное сллово на уникальное целое число и закодировать текст рецензии с помощью этих целых чисел (индексов уникальных слов);\n",
    "4. Разделить набор данных на мини-пакеты, которые будут служить входом для модели."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbbe6b0-d2db-4eda-ba36-2dfb48a3e6e4",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "### Загрузка датасета\n",
    "Загрузим датасет, подготовленный при выполнении предыдущего задания. Он содержит два столбца: \n",
    "- **review_text:**  исходный текст рецензии;\n",
    "- **sentiment_label:**  метка; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9533c76d-e5d6-48c3-ad02-5ddd9fc9aa6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('df.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6217503c-1e4a-4aa2-882a-fc699d133e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 2 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   review_text      50000 non-null  object\n",
      " 1   sentiment_label  50000 non-null  int8  \n",
      "dtypes: int8(1), object(1)\n",
      "memory usage: 439.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edd20bee-3894-44c8-99d9-45143a2480a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>sentiment_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bromwell High is a cartoon comedy. It ran at t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Homelessness (or Houselessness as George Carli...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brilliant over-acting by Lesley Ann Warren. Be...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         review_text  sentiment_label\n",
       "0  Bromwell High is a cartoon comedy. It ran at t...                1\n",
       "1  Homelessness (or Houselessness as George Carli...                1\n",
       "2  Brilliant over-acting by Lesley Ann Warren. Be...                1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88044969-2df7-4e2f-9baa-ad92e8ec872e",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "### Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0b811d7-f403-4daf-b8a4-4d26d92dbd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.review_text\n",
    "target = df.sentiment_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e26e430-d612-42c9-b8ef-3b4dd252f019",
   "metadata": {},
   "source": [
    "Шаг 1: сформируем tensorflow-датасет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "237ce366-7cbe-4150-8904-198aab00cb81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Bromwell High is a cartoon comedy. It ran at the s' 1\n",
      "b'Homelessness (or Houselessness as George Carlin st' 1\n",
      "b'Brilliant over-acting by Lesley Ann Warren. Best d' 1\n"
     ]
    }
   ],
   "source": [
    "# Создание набора данных\n",
    "ds_raw = tf.data.Dataset.from_tensor_slices((data.values, target.values))\n",
    "\n",
    "# Инспектирование\n",
    "for example in ds_raw.take(3):\n",
    "    tf.print(example[0].numpy()[:50], example[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f877057f-1dd5-41da-be23-42cf1c9dbf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(2023)\n",
    "ds_raw = ds_raw.shuffle(50000, reshuffle_each_iteration=False)\n",
    "\n",
    "ds_raw_test = ds_raw.take(25000)\n",
    "ds_raw_train_val = ds_raw.skip(25000)\n",
    "ds_raw_train = ds_raw_train_val.take(20000)\n",
    "ds_raw_val = ds_raw_train_val.skip(20000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf3c755-acc1-478d-b6fd-5282c7dff7b4",
   "metadata": {},
   "source": [
    "Шаг 2: найдём уникальные лексемы с помощью `Counter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4e34646-47c4-444d-94a3-9066dfbf7e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер словаря: 86808\n",
      "CPU times: total: 7.53 s\n",
      "Wall time: 8.79 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tokenizer = tfds.features.text.Tokenizer()\n",
    "token_counts = Counter()\n",
    "\n",
    "for example in ds_raw_train:\n",
    "    tokens = tokenizer.tokenize(example[0].numpy())\n",
    "    token_counts.update(tokens)\n",
    "    \n",
    "print(f'Размер словаря: {len(token_counts)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110f3119-d3b2-46c6-9be8-53c5fd398551",
   "metadata": {},
   "source": [
    "Шаг 3: закодируем уникальные лексемы целыми числами с помощью `tfds.features.text.TokenTextEncoder`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "478f2366-f14b-429f-abe3-2d2c4f11a872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[810, 57, 177, 3189]\n"
     ]
    }
   ],
   "source": [
    "encoder = tfds.features.text.TokenTextEncoder(token_counts)\n",
    "example_str = 'This is an example!'\n",
    "print(encoder.encode(example_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41eb7694-4621-4492-a2d9-b6deca2d2383",
   "metadata": {},
   "source": [
    "Определим вспомогательные функции:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1554369-8d5f-48f0-b54a-9d3a937b88cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(text_tensor, label):\n",
    "    text = text_tensor.numpy()\n",
    "    encoded_text = encoder.encode(text)\n",
    "    return encoded_text, label\n",
    "\n",
    "\n",
    "def encode_map(text, label):\n",
    "    return tf.py_function(encode, inp=[text, label],\n",
    "                          Tout=(tf.int64, tf.int8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e47abb65-020a-4756-922f-bfd5f26a1f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = ds_raw_train.map(encode_map)\n",
    "ds_val = ds_raw_val.map(encode_map)\n",
    "ds_test = ds_raw_test.map(encode_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d27fe5-0af6-4990-b806-052e641c1fd1",
   "metadata": {},
   "source": [
    "Выведем длины нескольких примеров из обучающей выборки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "562c8784-0ab7-46d7-a086-b237569da881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Длина последовательности: (459,)\n",
      "Длина последовательности: (235,)\n",
      "Длина последовательности: (165,)\n",
      "Длина последовательности: (151,)\n",
      "Длина последовательности: (223,)\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(2023)\n",
    "\n",
    "for example in ds_train.shuffle(1000).take(5):\n",
    "    print(f'Длина последовательности: {example[0].shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b29e983-e288-4a73-91fd-42a0fca7ee60",
   "metadata": {},
   "source": [
    "Разделим наборы на пакеты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d3336ca-aee5-491b-a89a-f019d7743ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = ds_train.padded_batch(32, padded_shapes=([-1],[]))\n",
    "val_data = ds_val.padded_batch(32, padded_shapes=([-1],[]))\n",
    "test_data = ds_test.padded_batch(32, padded_shapes=([-1],[]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e510652a-caf3-40f8-bc4c-aad4ab5dfd3e",
   "metadata": {},
   "source": [
    "---\n",
    "### Разработка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89833428-0f3f-4a73-9b77-3070567fd8bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embed_layer (Embedding)     (None, None, 20)          1736200   \n",
      "                                                                 \n",
      " bidir-lstm (Bidirectional)  (None, 128)               43520     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,788,041\n",
      "Trainable params: 1,788,041\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_dim=20\n",
    "vocab_size = len(token_counts) + 2\n",
    "\n",
    "tf.random.set_seed(2023)\n",
    "\n",
    "# построение модели\n",
    "bi_lstm_model = tf.keras.Sequential([\n",
    "    layers.Embedding(input_dim=vocab_size,\n",
    "                     output_dim=embedding_dim,\n",
    "                     name='embed_layer'), \n",
    "    layers.Bidirectional(\n",
    "        layers.LSTM(64, name='lstm_layer'),\n",
    "        name='bidir-lstm'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "bi_lstm_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6506e5-7414-499b-8be3-eeb5e490b0bf",
   "metadata": {},
   "source": [
    "Скомпилируем и обучим модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "965959df-269c-4d8a-9e70-42698ad2ab6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_lstm_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d61d8c-3d31-4efb-8542-483dd67e699c",
   "metadata": {},
   "source": [
    "В целях экономии времени попробуем обучить модель всего на двух эпохах:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34d1de84-a256-4446-bbb5-809e7dc5c110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "625/625 [==============================] - 383s 604ms/step - loss: 0.4956 - accuracy: 0.7617 - val_loss: 0.3822 - val_accuracy: 0.8486\n",
      "Epoch 2/2\n",
      "625/625 [==============================] - 365s 584ms/step - loss: 0.2465 - accuracy: 0.9082 - val_loss: 0.3818 - val_accuracy: 0.8562\n"
     ]
    }
   ],
   "source": [
    "history = bi_lstm_model.fit(\n",
    "    train_data,\n",
    "    validation_data=val_data,\n",
    "    epochs=2,\n",
    "    use_multiprocessing=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7a01f7-e110-4253-bcde-7a73650ba7c7",
   "metadata": {},
   "source": [
    "Проведём оценку построенной модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00b6f031-7cef-4665-9f7a-2bb879bc03e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 91s 117ms/step - loss: 0.3613 - accuracy: 0.8642\n",
      "Правильность при испытании: 0.8641600012779236\n"
     ]
    }
   ],
   "source": [
    "test_results = bi_lstm_model.evaluate(test_data)\n",
    "print(f'Правильность при испытании: {test_results[1]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
