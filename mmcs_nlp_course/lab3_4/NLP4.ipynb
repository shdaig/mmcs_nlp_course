{
 "cells": [
  {
   "cell_type": "raw",
   "id": "813dd9a8-5a16-49a7-bf60-4fb730134bdc",
   "metadata": {},
   "source": [
    "Голенищев Артём, ИИ-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26341c72-a3b9-4bcc-83e2-8f4c81b1dff6",
   "metadata": {},
   "source": [
    "---\n",
    "# Задание 4. Разработать модель RNN для генерации нового текста, похожего по стилю на текст во входном документе.\n",
    "\n",
    "- В качестве входных данных выберите  любой текст на сайте проекта \"Гутенберг\": https://www.gutenberg.org; ✅\n",
    "\n",
    "- Приведите примеры текстов, сгенерированных при трех различных значениях коэффициента *α* (температуры) (`scale_factor`). ✅\n",
    "\n",
    "### Отчетность\n",
    "Отчет по заданию должен быть оформлен в виде ноутбука с прокомментированным кодом и результатами запуска кода. Ноутбук с отчетом прикрепите к странице до 31 мая (включительно)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ffae7b-c50f-4660-a3cc-db9c44459f09",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "### Подключение модулей и библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b947804b-7451-4a8e-bad3-b5d876c0ca29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1415b890-5905-45e1-9463-c09642b3e20b",
   "metadata": {},
   "source": [
    "---\n",
    "### Чтение о обработка текста"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18047344-8c5b-447c-b396-10c14a447580",
   "metadata": {},
   "source": [
    "В качестве входных данных на сайте проекта Gutenberg был выбран роман Теодора Драйзера \"Финансист\": https://www.gutenberg.org/ebooks/1840."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c735e1fa-24fe-42c6-9e53-c6e1f61808e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Общая длина: 1092920\n",
      "Уникальные символы: 84\n",
      "CPU times: total: 15.6 ms\n",
      "Wall time: 31 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "with open('1840-0.txt', 'r', encoding=\"utf8\") as fp:\n",
    "    text = fp.read()\n",
    "    \n",
    "start_index = text.find('The Philadelphia into which Frank Algernon Cowperwood was born')\n",
    "end_index = text.find('End of the Project Gutenberg EBook of The Financier, by Theodore Dreiser')\n",
    "\n",
    "text = text[start_index:end_index]\n",
    "char_set = set(text)\n",
    "\n",
    "print(f'Общая длина: {len(text)}')\n",
    "print(f'Уникальные символы: {len(char_set)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0548c066-9894-4dc7-9b30-9a25cf643e50",
   "metadata": {},
   "source": [
    "Для удобства напишем несколько функций:\n",
    "- `char2int` возвращает отображение символов на целые числа;\n",
    "- `text2int` кодирует текст с помощью заданного отображения;\n",
    "- `int2text` декодирует текст с помощью заданного отображения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f002bb65-81e0-41a4-bae6-fb568666e2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def char2int(char_sorted) -> dict[str,int]:\n",
    "    return {ch:i for i,ch in enumerate(char_sorted)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "915ecec4-dc17-4296-8d8b-b2bfe2721b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2int(text, char_encoded) -> np.ndarray[int]:\n",
    "    return np.array([char_encoded[ch] for ch in text], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bb79ff7-ad9f-4518-9477-6084a9b18823",
   "metadata": {},
   "outputs": [],
   "source": [
    "def int2text(text_encoded, char_array) -> str:\n",
    "    return ''.join(char_array[text_encoded]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83b38c6-88e7-4f12-aab0-e783aa92bd8f",
   "metadata": {},
   "source": [
    "Проверим работоспособность функций, закодировав и декодировав первое предложение романа:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e932dd00-45e5-4471-8d49-3b990048f2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Закодированное первое предложение: [43 60 57  1 39 60 61 64 53 56 57 64 68 60 61 53  1 61 66 72 67  1 75 60\n",
      " 61 55 60  1 29 70 53 66 63  1 24 64 59 57 70 66 67 66  1 26 67 75 68 57\n",
      " 70 75 67 67 56  1 75 53 71  1 54 67 70 66  1 75 53 71  1 53  0 55 61 72\n",
      " 77  1 67 58  1 72 75 67  1 60 73 66 56 70 57 56  1 53 66 56  1 58 61 58\n",
      " 72 77  1 72 60 67 73 71 53 66 56  1 53 66 56  1 65 67 70 57  9]\n",
      "Декодированное первое предложение: The Philadelphia into which Frank Algernon Cowperwood was born was a\n",
      "city of two hundred and fifty thousand and more.\n"
     ]
    }
   ],
   "source": [
    "char_sorted = sorted(char_set)\n",
    "char_encoded = char2int(char_sorted)\n",
    "char_array = np.array(char_sorted)\n",
    "\n",
    "encoding_test_sample = text2int(text[:117], char_encoded)\n",
    "print(f'Закодированное первое предложение: {encoding_test_sample}')\n",
    "\n",
    "decoding_test_sample = int2text(encoding_test_sample, char_array)\n",
    "print(f'Декодированное первое предложение: {decoding_test_sample}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75116ab-ab74-4612-b214-3efab2f59738",
   "metadata": {},
   "source": [
    "Закодируем весь текст:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "498f0b10-157d-40ed-910b-2364c4f20434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape закодированного текста: (1092920,)\n"
     ]
    }
   ],
   "source": [
    "text_encoded = text2int(text, char_encoded)\n",
    "print(f'Shape закодированного текста: {text_encoded.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e97d976-e793-4e7f-99ce-0d34ff661b78",
   "metadata": {},
   "source": [
    "---\n",
    "### Формирование датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4faa749-4adb-4fe5-899c-8331422f11a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43 -> T\n",
      "60 -> h\n",
      "57 -> e\n",
      "1 ->  \n",
      "39 -> P\n"
     ]
    }
   ],
   "source": [
    "ds_text_encoded = tf.data.Dataset.from_tensor_slices(text_encoded)\n",
    "\n",
    "for example in ds_text_encoded.take(5):\n",
    "    print(f'{example.numpy()} -> {char_array[example.numpy()]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e694b81d-1062-4bc8-96ad-43c579940fde",
   "metadata": {},
   "source": [
    "Напишем функции для формирования x и y. \n",
    "<br> В `input_seq` записываются все символы из входного чанка, кроме последнего, а в `target_seq` - все, кроме первого. Таким образом, планируется прогнозировать один последующий символ на основе предыдущих:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fe97f1c-9306-4f91-b903-54a102c940e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_seq = chunk[:-1]\n",
    "    target_seq = chunk[1:]\n",
    "    return input_seq, target_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd884117-5527-4037-8a3b-7375a9cd9ecc",
   "metadata": {},
   "source": [
    "Извлечём из текста такие последовательности:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "063d1ece-2cc5-443e-957e-5e3f38c26913",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 40\n",
    "chunk_size = seq_length + 1\n",
    "\n",
    "ds_chunks = ds_text_encoded.batch(chunk_size, drop_remainder=True)\n",
    "ds_sequences = ds_chunks.map(split_input_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e58d88-6eb1-40f4-a71a-441fc7cdebae",
   "metadata": {},
   "source": [
    "Выведем несколько примеров преобразования:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33b82b52-bb69-4f8a-b8ba-f22a952133b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вход Х: 'The Philadelphia into which Frank Algern'\n",
      "Цель Y: 'he Philadelphia into which Frank Algerno'\n",
      "\n",
      "Вход Х: 'n Cowperwood was born was a\\ncity of two '\n",
      "Цель Y: ' Cowperwood was born was a\\ncity of two h'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for example in ds_sequences.take(2):\n",
    "    print(f'Вход Х: {repr(int2text(example[0].numpy(), char_array))}')\n",
    "    print(f'Цель Y: {repr(int2text(example[1].numpy(), char_array))}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8840bf4c-3847-48ac-8f71-2b0f51cdd158",
   "metadata": {},
   "source": [
    "Разделим данные на пакеты и посмотрим, что получилось на одном примере:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6127a6bf-a193-4c95-9601-fb9bdac1520d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вход Х:\n",
      "[[58 53 72 ... 60 67 73]\n",
      " [72  1 60 ... 53 54 67]\n",
      " [67 66  1 ... 61 71  1]\n",
      " ...\n",
      " [ 1 54 57 ... 64 57 53]\n",
      " [72  1 71 ... 63 66 57]\n",
      " [57 72  1 ... 72 60 57]]\n",
      "Цель Y:\n",
      "[[53 72 60 ... 67 73 71]\n",
      " [ 1 60 67 ... 54 67 73]\n",
      " [66  1 66 ... 71  1 75]\n",
      " ...\n",
      " [54 57 59 ... 57 53 71]\n",
      " [ 1 71 67 ... 66 57 57]\n",
      " [72  1 61 ... 60 57  1]]\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(2023)\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 10000\n",
    "ds = ds_sequences.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "\n",
    "for example in ds.take(1):\n",
    "    print(f'Вход Х:\\n{example[0]}')\n",
    "    print(f'Цель Y:\\n{example[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63711f7-33dc-4dd9-a844-540a21ccf703",
   "metadata": {},
   "source": [
    "---\n",
    "### Разработка модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a75acc-1efd-4855-95c6-d177d654cd40",
   "metadata": {},
   "source": [
    "Напишем функцию, формирующую модель с заданными параметрами:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16159352-a656-4e7f-9b09-ec9401531214",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units):\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Embedding(vocab_size, embedding_dim),\n",
    "        layers.LSTM(rnn_units, return_sequences=True),\n",
    "        layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e5e7b73-624a-470b-a5ca-097c16b7c546",
   "metadata": {},
   "outputs": [],
   "source": [
    "charset_size = len(char_array)\n",
    "embedding_dim = 256\n",
    "rnn_units = 512\n",
    "\n",
    "tf.random.set_seed(2023)\n",
    "model = build_model(vocab_size=charset_size, \n",
    "                    embedding_dim=embedding_dim,\n",
    "                    rnn_units=rnn_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "024d8d67-fbbf-4823-9a91-ebf9312e029e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 256)         21504     \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, None, 512)         1574912   \n",
      "                                                                 \n",
      " dense (Dense)               (None, None, 84)          43092     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,639,508\n",
      "Trainable params: 1,639,508\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c49bae-bdc0-426a-9ea4-27b0f5315249",
   "metadata": {},
   "source": [
    "Обучим модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "90f29758-7e96-49a8-86d5-8cd4981a672f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "417/417 [==============================] - 161s 379ms/step - loss: 2.3842\n",
      "Epoch 2/20\n",
      "417/417 [==============================] - 142s 339ms/step - loss: 1.8233\n",
      "Epoch 3/20\n",
      "417/417 [==============================] - 134s 321ms/step - loss: 1.6293\n",
      "Epoch 4/20\n",
      "417/417 [==============================] - 134s 319ms/step - loss: 1.5190\n",
      "Epoch 5/20\n",
      "417/417 [==============================] - 132s 315ms/step - loss: 1.4470\n",
      "Epoch 6/20\n",
      "417/417 [==============================] - 134s 320ms/step - loss: 1.3960\n",
      "Epoch 7/20\n",
      "417/417 [==============================] - 135s 321ms/step - loss: 1.3577\n",
      "Epoch 8/20\n",
      "417/417 [==============================] - 133s 319ms/step - loss: 1.3267\n",
      "Epoch 9/20\n",
      "417/417 [==============================] - 133s 318ms/step - loss: 1.3011\n",
      "Epoch 10/20\n",
      "417/417 [==============================] - 133s 318ms/step - loss: 1.2787\n",
      "Epoch 11/20\n",
      "417/417 [==============================] - 133s 319ms/step - loss: 1.2584\n",
      "Epoch 12/20\n",
      "417/417 [==============================] - 135s 321ms/step - loss: 1.2404\n",
      "Epoch 13/20\n",
      "417/417 [==============================] - 134s 320ms/step - loss: 1.2237\n",
      "Epoch 14/20\n",
      "417/417 [==============================] - 131s 314ms/step - loss: 1.2085\n",
      "Epoch 15/20\n",
      "417/417 [==============================] - 134s 320ms/step - loss: 1.1935\n",
      "Epoch 16/20\n",
      "417/417 [==============================] - 132s 316ms/step - loss: 1.1792\n",
      "Epoch 17/20\n",
      "417/417 [==============================] - 133s 318ms/step - loss: 1.1652\n",
      "Epoch 18/20\n",
      "417/417 [==============================] - 134s 321ms/step - loss: 1.1517\n",
      "Epoch 19/20\n",
      "417/417 [==============================] - 133s 318ms/step - loss: 1.1389\n",
      "Epoch 20/20\n",
      "417/417 [==============================] - 134s 320ms/step - loss: 1.1257\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', \n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))\n",
    "history = model.fit(ds, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b55d4ad-bdd5-4b9b-abb5-28235c2ce460",
   "metadata": {},
   "source": [
    "---\n",
    "### Генерация текста"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd662013-08e3-4d34-b287-a8a05cb18234",
   "metadata": {},
   "source": [
    "Подготовим функцию для генерации отрывка текста из фходной строки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0340b376-36b8-40d8-8f31-2d3bc3282c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(model, starting_str, len_generated_text=500, max_input_length=40, scale_factor=1.0):\n",
    "    encoded_input = text2int(starting_str, char_encoded)\n",
    "    encoded_input = tf.reshape(encoded_input, (1,-1))\n",
    "    \n",
    "    generated_str = starting_str\n",
    "    \n",
    "    model.reset_states()\n",
    "    for i in range(len_generated_text):\n",
    "        logits = model(encoded_input)\n",
    "        logits = tf.squeeze(logits, 0)\n",
    "        \n",
    "        scaled_logits = logits * scale_factor\n",
    "        new_char_index = tf.random.categorical(scaled_logits, num_samples=1)\n",
    "        \n",
    "        new_char_index = tf.squeeze(new_char_index)[-1].numpy()\n",
    "        \n",
    "        generated_str += str(char_array[new_char_index])\n",
    "        \n",
    "        new_char_index = tf.expand_dims([new_char_index], 0)\n",
    "        encoded_input = tf.concat([encoded_input, new_char_index], axis=1)\n",
    "        encoded_input = encoded_input[:, -max_input_length:]\n",
    "        \n",
    "    return generated_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81526336-b2db-431b-b3d8-7d46af2f0713",
   "metadata": {},
   "source": [
    "Сгенерируем три текста с разными коэффициентами *α*: `1.0`, `2.0` (больше связности в тексте) и `0.5` (меньше связности в тексте):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c924d0d6-9bbb-4f73-acb9-8def3767f296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The next morning, nevertheless short was a little norcenable than Stener’s, to whose favors were sure\n",
      "for open.\n",
      "\n",
      "“Well, you were system one, a harring Took of Fiftals and\n",
      "the side of gently. He had dressed the devoted to\n",
      "cover expected, why either he could do. “Good convict saw you.”\n",
      "\n",
      "Steger did it can. A will-stand, gentlemen, he might come to his eye befone himself.\n",
      "\n",
      "“Well, Alor remained Down the amount of the\n",
      "facts in this world after days by unranching him. The business office religious\n",
      "and affairs in some \n",
      "CPU times: total: 1min 14s\n",
      "Wall time: 40.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tf.random.set_seed(2023)\n",
    "print(sample(model, 'The next morning', scale_factor=1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63a352e0-5eff-461f-aec2-9a4cde791255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The next morning, and that he was comparatively the city and the fact that he was to be a little to par.”\n",
      "\n",
      "He paused and satisfied, with the idea of the properties of the street and he was to be so friends which were as a human mind was through the prison of this office of the home of the other three months of the morning, some of the fact that he was a little something to see\n",
      "the property of the stock exchange and the first to prison in the misus of all the fituation of his property, but that was becoming in t\n",
      "CPU times: total: 1min 15s\n",
      "Wall time: 40.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tf.random.set_seed(2023)\n",
    "print(sample(model, 'The next morning', scale_factor=2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7bd8afc6-1f85-45c0-a567-fbe7b00f257d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The next morning, neverthus.\n",
      "Thispet y0u.\n",
      "Little?” Their 1OhCubSI,\n",
      "did stow. We’ll?” Zas\n",
      "complethered\n",
      "Cowperwood to be mudbay-crin’—”)\n",
      "mernly Co!lvins Philbs\n",
      "Tegre Whard Assocke! He’ll\n",
      "golx’y accrulay perpoterateny, fath bey: agivem shrewd’s appene_ciarity, jusucquescoon, Squaket poveply.\n",
      "But her secertabilly trick. She pruttligged his chif\n",
      "wigh, there had Company’s taEkk; the\n",
      "voversness. This privical just proper, such otpletys, Thankison I’m try tif sooneat, with I’ll get noy: A notwfernoa han; PatamL_s effec\n",
      "CPU times: total: 1min 14s\n",
      "Wall time: 39.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tf.random.set_seed(2023)\n",
    "print(sample(model, 'The next morning', scale_factor=0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b66983a-22c6-4c5b-9618-10e21a4c28cd",
   "metadata": {},
   "source": [
    "Комментарий к результатам работы модели:\n",
    "\n",
    "- При *α*=`1.0` текст довольно бессвязный, однако имеет некую структуру и даже содержит явную прямую речь;\n",
    "- При *α*=`2.0` каждое последующее слово лучше связано с предыдущим, но текст сгенерирован практически единым предложением, что немного ухудшает впечатление о модели;\n",
    "- При *α*=`0.5` общий результат хуже: нейросеть выдумывает слова, использует неуместные символы (нижнее подчёркивание, восклицательные знаки и цифры в середине слов). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
